{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3c771b",
   "metadata": {},
   "source": [
    "**Behaviorism vs. Cognitivism**:\n",
    "\n",
    "   * **Behaviorism**: Views conditioning as a direct stimulus-response connection.\n",
    "   * **Cognitivism**: Focuses on mental representations (e.g., expectation) involved in conditioning.\n",
    "\n",
    "\n",
    "#### **Operant Conditioning (Skinnerian Conditioning)**\n",
    "\n",
    "- Focuses on voluntary behavior (e.g., pressing a lever).\n",
    "- Reinforcers: Stimuli that increase the likelihood of a behavior.\n",
    "- Punishment: Stimuli that decrease the likelihood of a behavior.\n",
    "- Gradually reinforcing closer approximations to the desired behavior like teaching a dog to touch a refrigerator by rewarding successive steps (approaching, touching, scratching).\n",
    "- * **Continuous reinforcement**: Every response is reinforced.\n",
    "- * **Partial reinforcement**: Not every response is reinforced; more resistant to extinction.\n",
    "\n",
    "Thought for a couple of seconds\n",
    "\n",
    "\n",
    "| **Types of conditioning** | **Classical**                                                                                            | **Operant**                                                                              |\n",
    "| ------------------------- | -------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |\n",
    "| **Difference**            | Involuntary behavior (reflex)<br>CS (sound) preceding reflex                                             | Voluntary behavior (press lever)<br>Reinforcement after behavior                         |\n",
    "| **Pioneers**              | Pavlov, Watson                                                                                           | Thorndike, Skinner                                                                       |\n",
    "| **Unique concepts**       | • Unconditioned stimulus<br>• Unconditioned response<br>• Conditioned stimulus<br>• Conditioned response | • Reinforcer<br>• Reinforcement<br>• Punishment<br>• Shaping<br>• Reinforcement schedule |\n",
    "| **Shared concepts**       | • Extinction<br>• Spontaneous recovery<br>• Generalization<br>• Discrimination                           | • Extinction<br>• Spontaneous recovery<br>• Generalization<br>• Discrimination           |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf6972",
   "metadata": {},
   "source": [
    "#### **Using RL Models in Human Behavior**\n",
    "\n",
    "- **Computational Modeling**:\n",
    "\n",
    "   * **Model Fitting**: Using algorithms to adjust model parameters so that the output resembles real-world human behavior.\n",
    "   * **Optimization Algorithms**: Used to find the best parameters to fit a model (e.g., Q-learning model in RL).\n",
    "\n",
    "- **Q-Learning**:\n",
    "\n",
    "   * A **model-free** approach in which the agent learns by updating the **Q-value** of actions based on rewards.\n",
    "\n",
    "- **Cost Function**:\n",
    "\n",
    "   - **Cost Function**: Measures the similarity between human and model actions in reinforcement learning.\n",
    "   - **Trajectory SRT**: Adapts a task to RL by converting real-life elements (lights and buttons) into on-screen interactions (mouse movements to specific locations).\n",
    "   - **Log-likelihood Calculation**: Determines the likelihood of specific actions under given states, used to assess model performance compared to human behavior.\n",
    "   - **Q-Learner Fitting**: Involves adjusting parameters (α, β, γ) to maximize the log-likelihood, essentially optimizing the model to match human behavior more closely.\n",
    "\n",
    "- **Optimization**:\n",
    "   - **Parameter Optimization**: Involves finding the optimal parameter values that minimize the difference between human behavior and model predictions (cost function). This is an optimization problem where the goal is to find the parameter set that reduces the error.\n",
    "   - **Minimizing the Error**: The function $f(p_1, p_2, \\dots, p_k)$ calculates the difference, and the objective is to minimize this error using methods like maximum likelihood estimation (MLE) or chi-square.\n",
    "   - **Grid Search**: A method to search the parameter space by evaluating the error function at fixed intervals. However, it becomes impractical with many parameters (curse of dimensionality), as the number of evaluations grows exponentially.\n",
    "   -  **Nelder-Mead Algorithm**: A more efficient alternative to grid search that requires fewer iterations to find a minimum.\n",
    "   -  **Optimized Parameters**: Once parameters are optimized, they can reveal insights about cognitive processes, such as how quickly individuals learn or update their Q-values, which may correlate with traits like IQ or working memory.\n",
    "\n",
    "---\n",
    "\n",
    "* **Reinforcement learning** has its origins in classical and operant conditioning, both studied extensively in animal behavior.\n",
    "* **Computational models** based on RL can replicate human and animal behavior, providing valuable insights into learning processes in cognitive science. These models help researchers understand how humans and animals make decisions, predict future actions, and adapt to their environment.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
