{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6d7392",
   "metadata": {},
   "source": [
    "* **ε-greedy**:\n",
    "    - Mostly **exploits**\n",
    "    - ε choice is random and doesn’t depend on how uncertain we are; \n",
    "    - Switches between exploration and exploitation **suddenly** and not smoothly.\n",
    "\n",
    "* **UCB**:\n",
    "    - Uses **uncertainty** (like confidence bounds) to decide what to try.\n",
    "    - If an action hasn’t been tried much, its uncertainty is high, so UCB will **explore** it more. \n",
    "    - As the algorithm learns more, **uncertainty decreases**, so it slowly shifts from exploring uncertain options to exploiting the best one. \n",
    "    - Transition from exploration to exploitation is **gradual** and based on actual confidence.\n",
    "\n",
    "* **Tabular Dynamic Programming**: finds a **global** solution, and is **guaranteed** to **converge** to the optimal solution.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
