{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e26f563",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Chapter 1**\n",
    "\n",
    "- **Association Rule Mining** (Descriptive ML) : relationships between variables (Basket Analysis)\n",
    "- **Subgroup Discovery** $\\to$ Supervides, Descriptive ML\n",
    "- Modus Operandi (Model Categorization by Mode of Operation):\n",
    "    - **Grouping Models**: Decision Trees\n",
    "    - **Grading Models**: SVM, Linear Regression\n",
    "- **Model Phases**: Training Phase $\\to$ Inference Phase (Prediction Phase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04849dcc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79001a5a",
   "metadata": {},
   "source": [
    "## **Chapter 2**\n",
    "\n",
    "- **Accuracy:** Fraction of correct predictions\n",
    "- **Error Rate:** 1 - Accuracy\n",
    "- **Recall or Sensitivity**: True Positive Rate out od all actual positives\n",
    "- **Specificity**: True Negative Rate\n",
    "- **Precision**: True Positive Rate out of all positive predictions\n",
    "- **F1 Score**: Better than accuracy, considers both precision and recall\n",
    "\n",
    "\n",
    "$\\text{Accuracy} = \\frac{TP + TN}{P + N}$ , $\\text{Recall} = \\frac{TP}{TP + FN}$ , $\\text{Specificity} = \\frac{TN}{TN + FP}$ , $\\text{Precision} = \\frac{TP}{TP + FP}$ , $\\text{F1 Score} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$\n",
    "\n",
    "- **ROC Curve (Receiver Operating Characteristic)** : Plot of **True Positive Rate (Sensitivity: y-axis)** vs **False Positive Rate (1 - Specificity: x-axis)**.\n",
    "\n",
    "#### Loss Functions\n",
    "\n",
    "| Loss Type        | Description                                         |\n",
    "| ---------------- | --------------------------------------------------- |\n",
    "| 0–1 Loss         | 1 if wrong prediction, 0 if correct                 |\n",
    "| Hinge Loss       | Penalizes predictions that are not confident enough |\n",
    "| Exponential Loss | Penalizes wrong predictions exponentially           |\n",
    "| Logistic Loss    | Smooth loss function related to probability         |\n",
    "| Squared Loss     | Penalizes squared error of margin                   |\n",
    "\n",
    "- **Assessing Ranking Performance** $\\to$ **Ranking Error Rate (RER)** $\\to$ Fraction of pairs of instances that are incorrectly ordered\n",
    "- **Assessing Class Probability** $\\to$ Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84532c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743ce9f",
   "metadata": {},
   "source": [
    "## **Chapter 3**\n",
    "\n",
    "- **Multi-class Classifiers**\n",
    "    - **Inherently non-binary: Decision Trees, Naïve Bayes\n",
    "    - **Inherently binary: SVM $\\to$ One-vs-All ($k$ classifiers), One-vs-One ($k(k-1)/2$ classifiers)\n",
    "\n",
    "| Approach    | Training complexity   | Inference complexity |\n",
    "| ----------- | --------------------- | -------------------- |\n",
    "| One-vs-Rest | $O(k m^\\alpha)$       | $O(k^\\beta)$         |\n",
    "| One-vs-One  | $O(k^2 (m/k)^\\alpha)$ | $O(k^2 \\beta)$       |\n",
    "\n",
    "* $k$: number of classes\n",
    "* $m$: number of instances\n",
    "* $\\alpha$, $\\beta$: algorithm-specific complexities\n",
    "\n",
    "#### ROC Curve for Multi-class\n",
    "\n",
    "   * **Macro-average:** Calculates ROC for each class separately, then averages the results equally across classes (ignores class imbalance).\n",
    "   * **Micro-average:**  Calculates ROC for all classes together, treating each instance equally (considers class imbalance).\n",
    "\n",
    "- Common loss functions:\n",
    "  - **Mean Squared Error (MSE):** Average of squared residuals.\n",
    "  - **Mean Absolute Error (MAE):** Average of absolute residuals.\n",
    "  - **Huber Loss:** Combines MSE and MAE, less sensitive to outliers.\n",
    "\n",
    "- **Low bias** → complex model\n",
    "- **Low variance** → simple model\n",
    "- **Evaluating Clustering Performance**\n",
    "    - With Ground Truth (We know the real groups)\n",
    "        - **Rand Index**: Measures similarity between two data clusterings.\n",
    "        - **Precision**, **Recall**, **F1 Score**\n",
    "    - Without Ground Truth\n",
    "        - **Davies-Bouldin Index**: Measures the average similarity ratio of each cluster with its most similar one.\n",
    "        - **Calinski-Harabasz Index**: Ratio of the sum of between-cluster dispersion to within-cluster dispersion.\n",
    "        - **Silhouette Coefficient**: Measures how similar an object is to its own cluster compared to other clusters.\n",
    "            - $ s = \\frac{b - a}{\\max(a,b)} $\n",
    "            -  $a$: average distance to points in the same cluster\n",
    "            -  $b$: average distance to points in the nearest other cluster\n",
    "            -  Values close to +1 → good clustering; close to 0 → borderline; negative → wrong cluster.\n",
    "    - **Evaluating Subgroups**:\n",
    "        - Chi-Squared Test: Measures the association between two categorical variables.\n",
    "        - Compare subgroup distributions with the overall distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549a7a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c6ecc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Chapter 4**\n",
    "\n",
    "- **Tree models** (supervised) = **non-linear relationships** (they split data based on rules, not lines) = logical = **easy to interpret**\n",
    "  - **Decision Trees** (single tree)\n",
    "  - **Random Forests** (many decision trees combined)\n",
    "  - **Gradient Boosting** (trees built sequentially to correct errors)\n",
    "- Data of splits:\n",
    "  - **Pure split**: each child has only one class (ideal)\n",
    "  - **Impure split** (Lower $\\to$ better): children have mixed classes (common in real life)\n",
    "    - Measure:\n",
    "      - **Gini Index**\n",
    "      - **Entropy**\n",
    "      - **Misclassification error**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880e078",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584e974",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Chapter 5**\n",
    "\n",
    "### **Distance metric** validity\n",
    "\n",
    "1. **Zero distance to itself:** $Dis(x, x) = 0$\n",
    "2. **Positive for different points:** $Dis(x, y) > 0$ if $x \\neq y$\n",
    "3. **Symmetry:** $Dis(x, y) = Dis(y, x)$\n",
    "4. **Triangle inequality:** $Dis(x, z) \\leq Dis(x, y) + Dis(y, z)$\n",
    "\n",
    "If the 2nd condition allows zero even if points differ, it's called a **pseudo-metric**.\n",
    "\n",
    "- K in KNN\n",
    "    - **Small k**: Low bias, High variance (sensitive to noise) ,overfitting\n",
    "    - **Large k**: High bias, Low variance (smoother decision boundary), underfitting\n",
    "    - **Optimal k**: usually between 3 and 10.\n",
    "    - Use cross-validation to find the best k for your data.\n",
    "    - **Weighted voting**: give more weight to closer neighbours.\n",
    "\n",
    "\n",
    "- **KNN Curse of Dimensionality**: In high-dimension $\\to$ distance between points becomes less meaningful distance $\\to$ hard to find nearest neighbours\n",
    "\n",
    "- **K-means**\n",
    "    - Uses Euclidean distance\n",
    "    - Need to know $k$\n",
    "    - Sensitive to initial centroids\n",
    "- **k-medoids**\n",
    "    - Use any distance metric\n",
    "    - More robust to noise/outliers but more expensive computationally (O(n²))\n",
    "    - Less sensitive to initial centroids\n",
    "- **Evaluate**:\n",
    "    - Inertia: total within-cluster scatter distance from the centroid.\n",
    "    - Silhouette score: measures how similar an object is to its own cluster compared to other clusters.\n",
    "        - Range: -1 to 1\n",
    "        - Higher = better clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae0c1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98baba5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Chapter 6**\n",
    "\n",
    "- **Least Squares Method** find that best-fitting line by minimizing squared errors in linear regression.\n",
    "- **Evaluating Regression Models**:\n",
    "    - **R² (Coefficient of Determination)**: Proportion of variance explained by the model.\n",
    "        - R² = 1: perfect fit\n",
    "        - R² = 0: no fit\n",
    "        - $R^2 = 1 - \\frac{\\mathrm{RSS}}{\\mathrm{TSS}}$ where:\n",
    "            - **Residual Sum of Squares**(RSS): $\\mathrm{RSS} = \\sum_{i=1}^n (f(x_i) - \\hat{f}(x_i))^2$\n",
    "            - **Total Sum of Squares**(TSS): $\\mathrm{TSS} = \\sum_{i=1}^n (f(x_i) - \\bar{f})^2$\n",
    "    - **Residual Plot**: \n",
    "    - **Mean Absolute Error (MAE)**: Average absolute difference between predicted and actual values.\n",
    "    - **Mean Squared Error (MSE)**: Average squared difference between predicted and actual values.\n",
    "    - **Root Mean Squared Error (RMSE)**: Square root of MSE, variance of the errors.\n",
    "- **Remove Effect of Outliers**:\n",
    "    - Residual Plot $\\to$ Retrain model\n",
    "    - Total Least Squares $\\to$ Adjusts for errors in both x and y\n",
    "- **Regularised Regression (Ridge Regression)**: Adds penalty term to reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3695509c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302dc838",
   "metadata": {},
   "source": [
    "## **Chapter 7**\n",
    "\n",
    "- **Statistics of central tendency:** Mean, Median, Mode\n",
    "- **Statistics of dispersion:** Variance, Standard deviation, Range, Midrange, Quantiles, Interquartile range\n",
    "- **Shape statistics:** Skewness, Kurtosis (Peak Sharpness)\n",
    "- **Feature Transformation**: \n",
    "    - **Calibration:** Assigns numbers to categories\n",
    "    - **Thresholding:** Converts numeric/ordinal features into boolean (e.g., age > 18 = True)\n",
    "    - **Discretisation:** Group ranges of values into bins (e.g., Low, Medium, High)\n",
    "- **Normalisation**\n",
    "    - **Min-Max normalisation:** Scales data between 0 and 1.\n",
    "    - **Z-score normalisation:** Centers data around mean 0 and standard deviation 1.\n",
    "- **Principal Component Analysis (PCA)**: PCA helps reduce redundancy (features) when features are correlated. It make some calculations to find two new not correlated features:\n",
    "  - **PC1**: First principal component, explains the most variation\n",
    "  - **PC2**: Second principal component, orthogonal to PC1, explains the next most variation\n",
    "- **PCA calculations Methods**:\n",
    "  -  **Singular Value Decomposition (SVD)**\n",
    "  -  **Eigenvalue decomposition**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d75a7d",
   "metadata": {},
   "source": [
    "---\n",
    "## **Chapter 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89822eca",
   "metadata": {},
   "source": [
    "- **Decision rules:**\n",
    "    - **Maximum a posteriori (MAP) decision rule:** Consider both likelihood and prior.\n",
    "    - **Maximum likelihood (ML) decision rule:** Consider only likelihood, assume priors are equal.\n",
    "- **Probability Distributions for Categorical Variables**\n",
    "    - **Multivariate Bernoulli distribution:** models presence or absence of words (0 or 1).\n",
    "    - **Multinomial distribution:** models counts of word occurrences (how many times each word appears).\n",
    "- **Naïve Bayes Classifier**: Assumes features are conditionally independent given the class label.\n",
    "- **Gaussian Mixture Models (GMM)**: Models data as a mixture of multiple Gaussian distributions.\n",
    "    - Goal: Estimate parameters (means μj, covariances Σj) of each Gaussian without knowing the class labels.\n",
    "    - Classify points: Need Parameters $\\to$ Needs lables\n",
    "    - Use **Expectation-Maximization (EM)** algorithm to estimate parameters\n",
    "        - Initialize parameters randomly $\\to$ E-step: calculate probabilities of each point belonging to each Gaussian ...\n",
    "        - ... $\\to$ M-step: update parameters based on probabilities $\\to$ Repeat until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e4fcb",
   "metadata": {},
   "source": [
    "---\n",
    "## **Chapter 9**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53802e1",
   "metadata": {},
   "source": [
    "- **Bootstrapping**: Train/Test on different samples of data $\\to$ reduce mistakes by one fixed training set\n",
    "- **Bagging** Aggregating: Create multiple bootstraps $\\to$ train multiple models $\\to$ combine predictions (Aggregate)\n",
    "    - Reduces variance\n",
    "- **Subspace Sampling**: Instead of using all features, you randomly pick only a small set of features for each model. \n",
    "    - Different models look at different parts of the data, so their errors won’t be the same. \n",
    "    - This helps the combined model (ensemble) perform better and avoid overfitting.\n",
    "- **Random Forest**: Ensemble of decision trees\n",
    "    - Each tree is trained on a different bootstrap sample of the data.\n",
    "    - Each split in the tree considers only a random aspect of data.\n",
    "    - Predictions are made by averaging the predictions of all trees (for regression) or by majority vote (for classification).\n",
    "- **Boosting**: Sequentially train models, each focusing on the errors of the previous one.\n",
    "    - Each model gives more weight to misclassified instances than correctly classified ones to learn from mistakes.\n",
    "    - Like: XGBoost, AdaBoost, LightGBM, Gradient Boosting\n",
    "- **Bias:** Error from wrong assumptions (systematic error). Mostly in simple models (e.g., linear regression for non-linear data)\n",
    "    - **Reduce** $\\to$ Boosting\n",
    "- **Variance:** Error from sensitivity to small fluctuations in the training set (overfitting). Mostly in complex models (e.g., decision trees).\n",
    "    - **Reduce** $\\to$ Bagging\n",
    "- **Total expected error** = Bias² + Variance + Irreducible error.\n",
    "- **Stacking:** Train multiple base models (e.g., decision trees, SVMs) and combine their predictions using a meta-model (e.g., logistic regression).\n",
    "- **t-test**: Statistical test to compare two models. If p-value < 0.05, models are significantly different.\n",
    "    - **Independent t-test**: Compares means of two independent groups (like comparing scores of men vs women).\n",
    "    - **Paired t-test**: Compares means of two related groups (like comparing scores of the same group before and after a treatment)\n",
    "    - **t-test, not good for Multiple datasets**\n",
    "- **Wilcoxon Signed-Rank Test**: Compare algorithms by finding performance differences per dataset, ranking absolute differences, summing positive and negative ranks, and using the smaller sum as the test statistic.\n",
    "- **Friedman Test**: Compare **more than two algorithms** over multiple datasets. Rank algorithms per dataset, find each algorithm’s average rank, and test if average rank differences show they perform differently.\n",
    "- **Post-hoc Tests (like Nemenyi Test)**: After diffrence revealed in Friedman test, we aim for **which pairs** of algorithms are different. $\\to$ Calculate a **Critical Difference (CD)** value $\\to$ If the difference between the average ranks of two algorithms is greater than CD, their performance difference is significant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5a810",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "## **Chapter 10**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b46341",
   "metadata": {},
   "source": [
    "| Task                       | Output Unit  | Loss Function      |\n",
    "| -------------------------- | ------------ | ------------------ |\n",
    "| Regression                 | Linear unit  | Mean Squared Error |\n",
    "| Binary Classification      | Sigmoid unit | Cross-entropy loss |\n",
    "| Multi-class Classification | Softmax unit | Cross-entropy loss |\n",
    "\n",
    "- **Sigmoid** outputs probabilities for two classes.\n",
    "- **Softmax** generalizes sigmoid for multi-class outputs, ensuring probabilities sum to 1.\n",
    "- **Gradient descent** is an iterative algorithm that updates weights to reduce loss, moves weights opposite to the gradient (slope) of the loss.\n",
    "    1. Calculate gradient (how loss changes w\\.r.t. weights).\n",
    "    2. Update weights by a small step (learning rate × gradient).\n",
    "    3. Repeat until loss stops decreasing.\n",
    "- **Back-propagation** computes gradients from the output layer back to the input layer for all weights efficiently using the **chain rule** of calculus.\n",
    "- **Improving Efficiency** and Speed of Training:\n",
    "    - **Batch Gradient Descent:** Uses the whole dataset per update. (SLOW)\n",
    "    - **Stochastic Gradient Descent (SGD):** Updates weights after each training example.\n",
    "    - **Mini-batch Gradient Descent:** Uses small groups (batches) of data per update (common in practice)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d8798",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **Chapter 11**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b239eb",
   "metadata": {},
   "source": [
    "- **Intrinsic xAI**: Explainability is built into the model itself (Decision Trees, Linear Regression, Naïve Bayes).\n",
    "- **Post-hoc xAI**: Explainability is added after the model is trained (e.g., LIME, SHAP).\n",
    "- **Gradient-based methods:** Use gradients (derivatives) to see how input changes affect output (mostly for neural networks).\n",
    "- **Surrogate-based methods:** create similar datapoints and pass model through input, later explain the model using simpler models (e.g., linear regression, decision trees) like **LIME** and **SHAP**.\n",
    "- **LIME Limitations**: \n",
    "    - Explanations can vary each time you run it (not very stable).\n",
    "    - Can be manipulated or fooled (adversarial risk).\n",
    "    - Computationally expensive because it builds a surrogate model for every instance.\n",
    "- **Example-based Explanations**\n",
    "  - **Counterfactual:** Show how changing features would change the prediction (what-if scenarios).\n",
    "  - **Adversarial Examples:** Small, possibly meaningless changes to inputs that flip predictions (helps understand model weaknesses).\n",
    "  - **Data Influence:** Measures how much each training sample affects the prediction.\n",
    "- **Global Explainability Methods**:\n",
    "    - **Probing:** Train simple models to examine what parts of a neural network (like hidden layers) learn (e.g., shapes, colors in images).\n",
    "- **Mechanistic Interpretability (MechInterp)** $\\to$ study indivisual neurons $\\to$ Use **causal interventions** (removing or altering neurons) to test effects on output\n",
    "- **Concept-based Explainability (e.g., TCAV)**: Helps explain *what* the model “looks for” when making decisions which is human understandable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214d008",
   "metadata": {},
   "source": [
    "---\n",
    "## **Chapter 12**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b2e5a",
   "metadata": {},
   "source": [
    "- **AutoML Core Components**\n",
    "    - **Search Algorithm**: Finds the best model and hyperparameters.\n",
    "        - **Random/Grid Search**: Randomly or systematically explores combinations of hyperparameters.\n",
    "            - **Grid Search:** Simple but does not scale well with many parameters.\n",
    "            - **Random Search:** Tries random points; better than grid for high dimensions, easy to parallelize.\n",
    "        - **Bayesian Optimization**: Uses past result to guide the search for better hyperparameters.\n",
    "            - Fit surrogate probabilistic model (e.g., Gaussian Process)\n",
    "            - Use an **acquisition function** (like Expected Improvement) to decide which hyperparameters to test next.\n",
    "            - Evaluate $\\to$ Update the surrogate model $\\to$ Repeat.\n",
    "        - **Hyperband**: Combines random search with early stopping to efficiently explore hyperparameter space.\n",
    "    - **Search Space**: Defines what models and hyperparameters to consider. **Hyperparameters**:\n",
    "        - **Categorical:** Choices like activation function (\"relu\", \"sigmoid\").\n",
    "        - **Numerical:** Continuous (learning rate) or integer (number of layers).\n",
    "        - **Conditional:** Some hyperparameters only matter if others have certain values (e.g., \"beta1\" only if using Adam optimizer).\n",
    "    - **Evaluation Mechanism**: Measures model performance\n",
    "        - Train/Validation/Test\n",
    "        - Cross-validation\n",
    "        - Multi-armed bandit (Treat each model/hyperparameter setting as a slot machine arm $\\to$ **Successive Halving**)\n",
    "            - **Hyperband**: Improved version of successive halving with improving configurations by Bayesian optimization.\n",
    "        - Learning curve analysis (Longer training, more data, early stopping)\n",
    "- **AutoML Problems**:\n",
    "    - **Algorithm Selection Problem**\n",
    "    - **Hyperparameter Optimization Problem (HPO)**\n",
    "    - **Combined Algorithm Selection and Hyperparameter Optimization (CASH)**\n",
    "    - **Neural Architecture Search (NAS)**\n",
    "    - **Few-shot Learning** (Learning from very few examples)\n",
    "\n",
    "**Surrogate Models**: These methods explain a complex (black-box) model by creating a simpler, easy-to-understand model called a surrogate. The surrogate model tries to imitate the behavior of the black-box model, but only locally—meaning around one specific example or instance you want to explain. (e.g., LIME, SHAP)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
